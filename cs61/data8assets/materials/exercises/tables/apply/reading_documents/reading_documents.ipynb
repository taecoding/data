{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "\n",
    "# These lines import the Numpy and Datascience modules.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# These lines load the tests.\n",
    "from client.api.assignment import load_assignment \n",
    "tests = load_assignment('reading_documents.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we have to work with data that aren't in CSV format, but instead come in some less nice form.  In this exercise, we'll look at the text of some Reuters news reports from 1987.  Our dataset doesn't include *all* the news reports from that year, but it includes 1,000 of them.  Reuters doesn't say how the articles were selected.\n",
    "\n",
    "We've put the text of all the articles in a file called `reuters.txt`.  The cell below loads that file into a single big string and prints a few thousand characters, which is just enough to see one full article and the start of the next.  (Don't try to print the whole thing, because it's very long.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell to load the dataset as one big string of text.\n",
    "with open('reuters.txt', 'r') as file:\n",
    "    big_reuters_string = file.read()\n",
    "\n",
    "print(\"{:.5000}\\n[...]\".format(big_reuters_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a bunch of weird text for each article.  Each article is separated from its neighbors by the string `\"***ARTICLE***\"`.\n",
    "\n",
    "**Question 1.** Use the String method `split` to make an array of the text of all the articles.  That is, each entry of this array should be the text of one article.  Put that array in a new table called `reuters` as a column with the name \"Raw text\".\n",
    "\n",
    "*Hint:* When you split the articles correctly, you should see that each article starts with `\"<reuters...\"` and ends with `\"...</reuters>\"`.  There should be 1,000 articles.\n",
    "\n",
    "*Hint 2:* As an example, `\"steamcleaner\".split(\"ea\")` is the same as `make_array('st', 'mcl', 'ner')`.  So you want to split the big string that contains all the data, splitting with the text `\"***ARTICLE***\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reuters = Table().with_column(\n",
    "        ...\n",
    "    )\n",
    "reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each article has a line containing its title that looks something like this:\n",
    "\n",
    "    <title>LYNG SETS TOUGH U.S. STANCE WITH JAPAN ON BEEF</title>\n",
    "\n",
    "You could find that yourself for a few of the articles, but it would be very tedious to do it for all 1,000 articles.  So we'll write code to do it instead.\n",
    "\n",
    "**Question 2.** Below, we've written a function called `get_text_in_markers` that will help you find the title text for an article.  Use it to write a function called `get_title`, which is also documented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function is provided for you to use.  Read at least\n",
    "# its documentation (the stuff at the beginning in red).\n",
    "# You can also type in get_text_in_markers? somewhere and\n",
    "# run it to see the documentation in a slightly nicer form.\n",
    "# We haven't used any tools you haven't seen yet, so it\n",
    "# wouldn't hurt to read the code itself, too.\n",
    "def get_text_in_markers(text, marker):\n",
    "    \"\"\"Finds the part of a piece of text that's between specified markers.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The text in which you want to find something.\n",
    "    marker : str\n",
    "        The name of the marker that delimits the part of the\n",
    "        text you want to grab.  In the text itself, this string\n",
    "        will be surrounded by \"<>\" or \"</>\", but don't include\n",
    "        those angle brackets in this argument.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The parts of the text that are inside the markers.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> get_text_in_markers(\"stuff <interesting>yay exciting</interesting> more stuff\", \"interesting\")\n",
    "    'yay exciting'\n",
    "    \"\"\"\n",
    "    start_marker = \"<{}>\".format(marker)\n",
    "    end_marker = \"</{}>\".format(marker)\n",
    "    split_before = np.array(text.split(start_marker))\n",
    "    marker_text_and_after = split_before.item(1)\n",
    "    split_on_end_marker = np.array(marker_text_and_after.split(end_marker))\n",
    "    return split_on_end_marker.item(0)\n",
    "\n",
    "# Fill in this function.\n",
    "def get_title(article_text):\n",
    "    \"\"\"Takes the text of an article and returns its title.\"\"\"\n",
    "    ...\n",
    "\n",
    "# When you're done, this should produce 'LYNG SETS TOUGH U.S. STANCE WITH JAPAN ON BEEF'.\n",
    "get_title(reuters.column(\"Raw text\").item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Now use your function to find the title of every article in `reuters`.  Create a new table called `with_titles` that's a copy of `reuters` with an extra column named \"Title\" that contains these titles.\n",
    "\n",
    "*Note:* This might take a few seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_titles = ...\n",
    "with_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll go through a similar process to get the date of each article.  In each article, the date is on its own line, separated from the rest of the article by `<date>` and `</date>` markers.  You can check one of the articles for an example.\n",
    "\n",
    "**Question 4.** Write a function called `get_date`.  It should take as its argument the whole text of an article and return the date.  The date should be just the day of the year (so January 1 is day 1, and February 1 is day 32, since January has 31 days).  Note that all the articles are from the year 1987, so the year is irrelevant.\n",
    "\n",
    "We've written a function called `date_string_to_day` that will help you do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function is provided for you to use.  Read at least\n",
    "# its documentation (the stuff at the beginning in red).\n",
    "def date_string_to_day(date_string):\n",
    "    \"\"\"Converts a string that looks like a date into the day of the year.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    date_string : str\n",
    "        Text that contains a date in any reasonable format.\n",
    "        For example, \"September 13, 1994\" or \"9/13/94\" or\n",
    "        \"13-SEP-1994 15:02:20.00\" all work.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The day of the year that the date represents.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> date_string_to_day(\"January 3, 2016\")\n",
    "    3\n",
    "    \n",
    "    >>> date_string_to_day(\"February 4, 2000\")\n",
    "    35\n",
    "    \"\"\"\n",
    "    from dateutil import parser\n",
    "    import re\n",
    "    # Some of the Reuters dates have extraneous text at the end.\n",
    "    # This removes that text.\n",
    "    date_part = re.sub(\" [A-Z]*$\", \"\", date_string)\n",
    "    try:\n",
    "        date = parser.parse(date_part)\n",
    "    except:\n",
    "        print(\"Failed on\", date_string)\n",
    "    day_in_year = date.timetuple().tm_yday\n",
    "    return day_in_year\n",
    "\n",
    "# Fill in this function.\n",
    "def get_date(article_text):\n",
    "    date_text = ...\n",
    "    day_in_year = ...\n",
    "    ...\n",
    "\n",
    "# When you're done, this should produce 92.\n",
    "get_date(reuters.column(\"Raw text\").item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Use your function to find the date of every article in `with_titles`. Create a new table called `with_dates` that's a copy of `with_titles` with an extra column named \"Date\" that contains the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_dates = ...\n",
    "with_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** There was a series of earthquakes in Ecuador on March 6, 1987.  Most Reuters news stories about Ecuador from that period were related to the earthquake or its political and economic consequences.  Find out when Reuters reported on the earthquake by making a histogram of all the dates of the articles whose *titles* include the word `\"ECUADOR\"`.  Use bins of width 3.\n",
    "\n",
    "*Hint:* The function `are.containing` creates a predicate that matches strings that contain a given string.  You can find its documentation by running `are.containing?`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use these bins:\n",
    "bins = np.arange(0, 375, 3)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.** Make another histogram of the same data, but this time using different bins.  The first bin should start at day 0, and each bin should have a width of 10 days. Then, **using only your own inspection of the histogram (and no other Python code)**, estimate the proportion of Ecuador articles that were reported between days 50 and 100 of the year (including day 50 but not day 100). (The proportion should be out of the total number of articles whose titles include \"ECUADOR\".) Give that number the name `proportion_50_to_100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a histogram as described above.  (Be sure to use the\n",
    "# bins described in the question.)\n",
    "...\n",
    "\n",
    "# By inspecting your histogram, estimate the proportion of\n",
    "# Ecuador articles that were reported between days 50 and 100\n",
    "# of the year.  (It's hard to get exactly the right answer\n",
    "# from a histogram like this, so it's okay if your answer is\n",
    "# off by a little bit.)\n",
    "proportion_50_to_100 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.** Your histogram should show several long gaps in coverage about Ecuador during the year.  By exploring the dataset, try to explain this.  Use the code cell below for your explorations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "# Use this cell to answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import os\n",
    "_ = [tests.grade(q[:-3]) for q in os.listdir(\"tests\") if q.startswith('q')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this cell to submit your work *after* you have passed all of the test cells.\n",
    "# It's ok to run this cell multiple times. Only your final submission will be scored.\n",
    "\n",
    "!TZ=America/Los_Angeles ipython nbconvert --output=\".reading_documents_$(date +%m%d_%H%M)_submission.html\" reading_documents.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

